### 图像分割问题综述

​    图像的语义分割是将输入图像中的每个像素分配一个语义类别，已得到像素化的密集分类。

2014 年 Long 等人首次使用全卷积神经网络对自然图像进行端到端分割，语义分割 有了重大的突破。

​    全卷积网络（FCNs）可以用于自然图像的语义分割、多模态医学图像分析和多光谱卫星图像分割。与AlexNet 、VGG、ResNet 等深度分类网络类似，FCNs 也有大量进行语义分割的深层架构。

#### **网络框架**

​    一般的语义分割架构可以被认为是一个编码器 -- 解码器网络。编码器通常是一个预训练的分类网络，像VGG、ResNet，然后是一个解码器网络。这些架构之间的不同主要在于解码器网络，解码器的任务是将编码器学习到的可辨别特征（较低分辨率）从语义上映射到像素空间（较高分辨率），已获得密集分类。

​    不同于分类任务中深度网络最终结果（即类存在的概率）被视为唯一重要的事，语义分割不仅需要在像素级有判别能力，还需要有能将编码器在不同阶段学到的可判别特征映射到像素空间的机制，不同的机制（跳远连接、金字塔池化等）作为解码机制的一部分。

#### **Fully Convolution Networks (FCNs) 全卷积网络**

​    将当前的分类网络（AlexNet, VGG net 和 GoogLeNet）修改为全卷积网络，通过对分割任务进行微调，将它们学习的表征转移到网络中。然后，定义一种新的结构，它将深的、粗糙的网络层语义信息和浅的、精细的网络层的表层信息结合起来，生成精细的分割。

**关键特点：**

​    特征是由编码器中的不同阶段合并而成的，它们在语义信息的粗糙程度上有所不同。

​    低分辨率语义特征图的上采样使用通过双线性插值滤波器初始化的反卷积操作完成。

​    从 VGG16、Alexnet 等现代分类器网络进行知识转移的优秀样本来实现语义细分。

​    像 VGG16 分类网络的全连接层（fc6，fc7）被转换为全卷积层。它生成了一个低分辨率的类的热图，然后用双线性初始化的反卷积，并在上采样的每一个阶段通过融合（简单地相加）VGG16 中的低层（conv4和conv3）的更加粗糙但是分辨率更高的特征图进一步细化特征。

​    在传统的分类 CNNs 中，池化操作用来增加视野，同时减少特征图的分辨率。这对于分类任务来说非常有用，因为分类的最终目标是找到某个特定类的存在，而对象的空间位置无关紧要。因此，在每个卷积块之后引入池化操作，以使后续块能够从已池化的特征中提取更多抽象、突出类的特征。

​    池化和带步长的卷积对语义分割是不利的，因为这些操作造成了空间信息的丢失。

​    解码器中使用了不同的机制，但目的都在于恢复在编码器中降低分辨率时丢失的信息。

​    第一个卷积层捕捉低层次的几何信息，因为这完全依赖数据集，你可以注意到梯度调整了第一层的权重以使模型适应数据集。VGG 中更深层的卷积层有非常小的梯度流，因为这里捕获的高层次的语义概念足够用于分割。

​    语义分割架构的另一个重要方面是，对特征图使用反卷积，将低分辨率分割图上采样至输入图像分辨率机制，或者花费大量计算成本，使用空洞卷积在编码器上部分避免分辨率下降

#### **SegNet**

​    SegNet 的新颖之处在于解码器对其较低分辨率的输入特征图进行上采样的方式。具体地说，解码器使用了在相应编码器的最大池化步骤中计算的池化索引来执行非线性上采样。这种方法消除了学习上采样的需要。经上采样后的特征图是稀疏的，因此随后使用可训练的卷积核进行卷积操作，生成密集的特征图。

**关键特点：**

​    SegNet 在解码器中使用去池化对特征图进行上采样，并在分割中保持高频细节的完整性。

编码器不使用全连接层（和 FCN 一样进行卷积），因此是拥有较少参数的轻量级网络。

​    编码器中的每一个最大池化层的索引都存储了起来，用于之后在解码器中使用那些存储的索引来对相应特征图进行去池化操作。这有助于保持高频信息的完整性，但当对低分辨率的特征图进行去池化时，它也会忽略邻近的信息。

#### **U-Net**

​    U-Net 架构包括一个捕获上下文信息的收缩路径和一个支持精确本地化的对称扩展路径。这样一个网络可以使用非常少的图像进行端到端的训练。

**关键特点：**

​    U-Net 简单地将编码器的特征图拼接至每个阶段解码器的上采样特征图，从而形成一个梯形结构。该网络非常类似于 Ladder Network 类型的架构。

通过跳远拼接连接的架构，在每个阶段都允许解码器学习在编码器池化中丢失的相关特性。

#### **Fully Convolutional DenseNet**

​    全卷积 DenseNet 使用 DenseNet 作为它的基础编码器，并且也以类似于 U-Net 的方式，在每一层级上将编码器和解码器进行拼接。

#### **E-Net 和 Link-Net**

​    一种新的深度神经网络架构，称为 ENet（efficient neural network），专门为需要低延迟操作的任务创建。

​    LinkNet 架构类似于一个梯形网络架构，编码器的特征图（横向）和解码器的上采样特征图（纵向）相加。

#### **Mask R-CNN**

​    该方法被称为 Mask R-CNN，以 Faster R-CNN 为基础，在现有边界框识别分支基础上添加一个并行的预测目标掩码的分支。

Mask R-CNN 架构相当简单，它是流行的 Faster R-CNN 架构的扩展，在其基础上进行必要的修改，以执行语义分割。

**关键特点：**

在 Faster R-CNN 上添加辅助分支以执行语义分割。

对每个实例进行的 RoIPool 操作已经被修改为 RoIAlign ，它避免了特征提取的空间量化，因为在最高分辨率中保持空间特征不变对于语义分割很重要。

Mask R-CNN 与 Feature Pyramid Networks（类似 于PSPNet，它对特征使用了金字塔池化）相结合，在 MS COCO 数据集上取得了最优结果。

在 2017-06-01 的时候，在网络上还没有 Mask R-CNN 的工作实现，而且也没有在 Pascal VOC 上进行基准测试，但是它的分割掩码显示了它与真实标注非常接近。

#### **PSPNet**

​    利用基于不同区域的上下文信息集合，通过我们的金字塔池化模块，使用金字塔场景解析网络（PSPNet）来发挥全局上下文信息的能力.PSPNet  为像素级的预测提供了一个更好的框架，该方法得到了最优性能。

**关键特点**

​     PSPNet 通过引入空洞卷积来修改基础的 ResNet 架构，特征经过最初的池化，在整个编码器网络中以相同的分辨率进行处理（原始图像输入的 1/4），直到它到达空间池化模块。

​    在 ResNet 的中间层中引入辅助损失，以优化整体学习。

​    在修改后的 ResNet 编码器顶部的空间金字塔池化聚合全局上下文。

#### **RefineNet**

​     RefineNet，一个通用的多路径优化网络，它明确利用了整个下采样过程中可用的所有信息，使用远程残差连接实现高分辨率的预测。通过这种方式，可以使用早期卷积中的细粒度特征来直接细化捕捉高级语义特征的更深的网络层。RefineNet 的各个组件使用遵循恒等映射思想的残差连接，这允许网络进行有效的端到端训练。

​    RefineNet 解决了传统卷积网络中空间分辨率减少的问题，与 PSPNet（使用计算成本高的空洞卷积）使用的方法非常不同。提出的架构迭代地池化特征，利用特殊的 RefineNet 模块增加不同的分辨率，并最终生成高分辨率的分割图。

**关键特点**

​     使用多分辨率作为输入，将提取的特征融合在一起，并将其传递到下一个阶段。

​     引入链式残差池化，可以从一个大的图像区域获取背景信息。它通过多窗口尺寸有效地池化特性，			       利用残差连接和学习权重方式融合这些特征。

​     所有的特征融合都是使用 sum（ResNet 方式）来进行端到端训练。

​     使用普通 ResNet 的残差层，没有计算成本高的空洞卷积。

#### **G-FRNet**

​     Gated Feedback Refinement Network (G-FRNet)，这是一种用于密集标记任务的端到端深度学习框架，解决了现有方法的局限性。最初，GFRNet 进行粗略地预测，然后通过在细化阶段有效地集成局部和全局上下文信息，逐步细化细节。我们引入了控制信息前向传递的门控单元，以过滤歧义.

#### **总结**

​     上述大多数架构都依赖于从**编码器到解码器**的简单特征，使用拼接、去池化或简单的加和。然而，在编码器中，从高分辨率（较难判别）层到对应的解码器中相应的上采样特征图的信息，不确定是否对分割有用。在每个阶段，通过使用门控细化反馈单元，控制从编码器传送到解码器的信息流，这样可以帮助解码器解决歧义，并形成更相关的门控空间上下文。 

​     另一方面，本文的实验表明，在语义分割任务中，ResNet网路是一个远优于 VGG16 的编码器。



### 关于语义分割一些代表性论文如下（按照提出时间排序）：

1. [FCN](http://link.zhihu.com/?target=http%3A//blog.qure.ai/notes/semantic-segmentation-deep-learning-review%23fcn)
2. [SegNet](http://link.zhihu.com/?target=http%3A//blog.qure.ai/notes/semantic-segmentation-deep-learning-review%23segnet)
3. [Dilated Convolutions](http://link.zhihu.com/?target=http%3A//blog.qure.ai/notes/semantic-segmentation-deep-learning-review%23dilation)
4. [DeepLab (v1 &amp;amp;amp;amp; v2)](http://link.zhihu.com/?target=http%3A//blog.qure.ai/notes/semantic-segmentation-deep-learning-review%23deeplab)
5. [RefineNet](http://link.zhihu.com/?target=http%3A//blog.qure.ai/notes/semantic-segmentation-deep-learning-review%23refinenet)
6. [PSPNet](http://link.zhihu.com/?target=http%3A//blog.qure.ai/notes/semantic-segmentation-deep-learning-review%23pspnet)
7. [Large Kernel Matters](http://link.zhihu.com/?target=http%3A//blog.qure.ai/notes/semantic-segmentation-deep-learning-review%23large-kernel)
8. [DeepLab v3](http://link.zhihu.com/?target=http%3A//blog.qure.ai/notes/semantic-segmentation-deep-learning-review%23deeplabv3)

#### FCN 网络：

主要贡献：

- 推广端到端卷积网络在语义分割领域中的应用
- 修改ImageNet预训练模型并应用于图像语义分割
- 采用解卷积层（deconvolutional layer）实现上采样
- 引入跳跃连接（skip connections）改善上采样的粒度（coarseness ）

相关解译：

论文的关键点在于分类网络模型中全连接层可以看作使用卷积核覆盖整个输入区域的卷积操作。这相当于基于重叠的输入块评估原始分类网络，但由于图像块重叠部分的计算共享，使得这种方法更高效。尽管这些结论并不是这篇论文独有的（参考[Integrated Recognition, Localization and Detection using Convolutional Networks](http://link.zhihu.com/?target=https%3A//arxiv.org/abs/1312.6229)，[There is a trend at CVPR 2015 of renaming existing deep learning techniques following minor modifications](http://link.zhihu.com/?target=https%3A//plus.google.com/%2BPierreSermanet/posts/VngsFR3tug9)），但是大大提升了VOC2012数据集上语义分割的性能。

![img](https://pic4.zhimg.com/80/v2-b55b025a40d279b5d2d2c17f5453e013_hd.jpg)

全卷积层作为卷积层（源于：[[1411.4038\] Fully Convolutional Networks for Semantic Segmentation](http://link.zhihu.com/?target=https%3A//arxiv.org/abs/1411.4038)）

将VGG等ImageNet预训练网络中的全连接层卷积化之后，由于CNNs中的池化操作，网络中的特征图还需要上采样操作。不同于简单的双线性插值，论文中解卷积层从数据中学习插值的相关参数。解卷积层也被称作：上卷积（upconvolution），完全卷积（full convolution），转置卷积（transposed convolution）或者微步卷积（fractionally-strided convolution）。

但是，由于池化操作造成的信息损失，上采样（即使采用解卷积操作）只能生成粗略的分割结果图。因此，论文从高分辨率的特征图中引入跳跃连接（shortcut/skip connection）操作改善上采样的精细程度。

- FCN对于语义分割领域来说贡献巨大，但当前的方法已经取得了很大的提升。

#### SegNet

> SegNet: A Deep Convolutional Encoder-Decoder Architecture for Image Segmentation
> Submitted on 2 Nov 2015
> [Arxiv Link](http://link.zhihu.com/?target=https%3A//arxiv.org/abs/1511.00561)

主要贡献：

- 将最大池化索引（Maxpooling indices）转换到解码器，从而提升分割分辨率。

相关解释：

尽管FCN网络中使用了解卷积层和少量跳跃连接，但输出的分割图比较粗略，因此本文引入更多的跳跃连接。但是，SegNet并没有复制FCN中的编码器特征，取而代之的是复制最大池化索引。因此，SegNet相对于FCN来说更节省内存。

![img](https://pic3.zhimg.com/80/v2-2de11324a6b2f74b5a5c00fc76dddd86_hd.jpg)

- FNC和SegNet都是最早提出编码器-解码器结构的网络
- SegNet架构的基准测试分数一般，不建议继续使用

#### Dilated Convolutions

> Multi-Scale Context Aggregation by Dilated Convolutions
> Submitted on 23 Nov 2015
> [Arxiv Link](http://link.zhihu.com/?target=https%3A//arxiv.org/abs/1511.07122)

主要贡献：

- 采用空洞卷积（dilated convolution）作为能够实现像素级预测的卷积层
- 提出“背景模块”（context module），用于空洞卷积的多尺度聚合

解释：

池化操作能够增加接受野，从而提升分类网络模型的性能。但是池化操作会降低分辨率，并不是语义分割的最佳方法。因此，作者提出空洞卷积层，其工作原理如下：

 

![img](https://pic1.zhimg.com/v2-4959201e816888c6648f2e78cccfd253_b.gif)

空洞/带孔卷积（Dilated/Atrous Convolutions，源于：[vdumoulin/conv_arithmetic](http://link.zhihu.com/?target=https%3A//github.com/vdumoulin/conv_arithmetic)）

空洞卷积层（[DeepLab](http://link.zhihu.com/?target=http%3A//blog.qure.ai/notes/semantic-segmentation-deep-learning-review%23deeplab)中称作带孔卷积层）能够不减少空间维度的前提下，使感受野呈现指数级增长。

从预训练分类网络（VGG）中移除最后的两个池化层，之后的卷积层均采用空洞卷积。模型设置pool-3和pool-4层之间所有卷积层的扩张程度（dilation）为2，pool-4之后卷积层的空洞值（dilation）为4。上述模块在论文中称作前端模块（frontend module），使用上述模块之后，无需增加参数即可实现密集的像素级类别预测。另一个模块在论文中称作上下文模块（context module），使用前端模块的输出作为输入单独训练。该模块由多个不同扩张程度（dilation）的空洞卷积级联而成，因此能够聚合不同尺度的上下文信息，从而改善前端模块输出的预测结果。

- 预测分割图的大小是原始图大小的1/8，几乎所有的方法都是这样，一般通过插值得到最终的分割结果。

#### DeepLab (v1 & v2)

> v1 : Semantic Image Segmentation with Deep Convolutional Nets and Fully Connected CRFs
> Submitted on 22 Dec 2014
> [Arxiv Link](http://link.zhihu.com/?target=https%3A//arxiv.org/abs/1412.7062)
> v2 : DeepLab: Semantic Image Segmentation with Deep Convolutional Nets, Atrous Convolution, and Fully Connected CRFs
> Submitted on 2 Jun 2016
> [Arxiv Link](http://link.zhihu.com/?target=https%3A//arxiv.org/abs/1606.00915)

主要贡献：

- 采用了带孔/空洞卷积（atrous/dilated convolution）
- 提出了金字塔型的空洞池化（atrous spatial pyramid pooling，ASPP）
- 采用全连接的CRF

解释：

带孔/空洞卷积层能够不增加参数的情况下扩大感受野，网络结构的修改详情见[空洞卷积论文（dilated convolutions paper）](http://link.zhihu.com/?target=http%3A//blog.qure.ai/notes/semantic-segmentation-deep-learning-review%23dilation)。

通过将原始图的不同尺度传递到CNN网络的并行分支（图像金字塔）中，或者使用不同采样率的多个并行空洞卷积层（ASPP），实现多尺度处理。

结构化的预测可以通过全连接的CRF实现，CRF的训练或微调作为后处理的步骤单独进行。

![img](https://pic1.zhimg.com/80/v2-4060ee4d0352000c53d966b0046a4432_hd.jpg)

DeepLab2流程图.（源于：[Semantic Image Segmentation with Deep Convolutional Nets, Atrous Convolution, and Fully Connected CRFs](http://link.zhihu.com/?target=https%3A//arxiv.org/abs/1606.00915)）

Benchmarks (VOC2012)：

> Score　　Comment　　　　　　　　　　　　　　　　　　　Source
> 79.7　　ResNet-101 + atrous Convolutions + ASPP + CRF　　[leaderboard](http://link.zhihu.com/?target=http%3A//host.robots.ox.ac.uk%3A8080/leaderboard/displaylb.php%3Fcls%3Dmean%26challengeid%3D11%26compid%3D6%26submid%3D6103%23KEY_DeepLabv2-CRF)

 

#### RefineNet

> RefineNet: Multi-Path Refinement Networks for High-Resolution Semantic Segmentation
> Submitted on 20 Nov 2016
> [Arxiv Link](http://link.zhihu.com/?target=https%3A//arxiv.org/abs/1611.06612)

主要贡献：

- 编码器-解码器架构拥有精心设计的解码器模块
- 所有组件采用残差连接（residual connection）的设计

解释：

采用空洞/带孔卷积的方法也存在缺点。空洞卷积需要大量的高分辨率特征图，因此对计算量和内存的消耗都很大，这也限制方法无法应用于高分辨率的精细预测。例如[DeepLab](http://link.zhihu.com/?target=http%3A//blog.qure.ai/notes/semantic-segmentation-deep-learning-review%23deeplab)中分割结果图采用原始输入图像的1/8大小。

因此，论文提出一种编码器-解码器的架构。编码器是ResNet-101模块，解码器则是RefineNet模块，其连接/融合编码器的高分辨率特征和先前RefineNet块中的低分辨率特征。

![img](https://pic4.zhimg.com/80/v2-a3d32638990c47a8468ffc9a382f0bff_hd.jpg)

 

RefineNet架构.（源于：[[1611.06612\] RefineNet: Multi-Path Refinement Networks for High-Resolution Semantic Segmentation](http://link.zhihu.com/?target=https%3A//arxiv.org/abs/1611.06612)）

每一个RefineNet模块都有两个组件，一个组件通过对低分辨率特征的上采样操作融合不同的分辨率特征，另一个组件基于步幅为1、大小为5*5的重复池化层来获取背景信息。这些组件遵循单位映射（identity map）的思想，并采用了残差连接（residual connection）的设计。

![img](https://pic7.zhimg.com/80/v2-2d7086036071ec08dff40769597f1d1e_hd.jpg)

RefineNet模块.（源于：[[1611.06612\] RefineNet: Multi-Path Refinement Networks for High-Resolution Semantic Segmentation](http://link.zhihu.com/?target=https%3A//arxiv.org/abs/1611.06612)）

#### PSPNet

> Pyramid Scene Parsing Network
> Submitted on 4 Dec 2016
> [Arxiv Link](http://link.zhihu.com/?target=https%3A//arxiv.org/abs/1612.01105)

主要贡献：

- 提出金字塔池化模块帮助聚合上下文信息
- 采用了辅助损失（auxiliary loss）

解释：

全局的场景分类能够提供图像语义分割的类别分布信息，因此非常重要。金字塔池化模块（pyramid pooling module）通过使用较大核的池化层获取这些信息。如上述[空洞卷积论文（dilated convolutions paper）](http://link.zhihu.com/?target=http%3A//blog.qure.ai/notes/semantic-segmentation-deep-learning-review%23dilation)中所述，PSPNet也使用了空洞卷积改善ResNet，并增加了金字塔池化模块。金字塔池化模块连接ResNet的特征图和并行池化层的上采样结果，其中，并行池化层分别采用核大小为整幅、一半和小部分图像的卷积核。

在ResNet的第四个阶段之后（即输入到金字塔池化模块的阶段），在主分支损失（ loss on main branch）之外增加了辅助损失。这种思想在其他论文中也被称作中间监管（intermediate supervision）。

![img](https://pic2.zhimg.com/80/v2-ed8c07b9fc0845d17acb639c97343a36_hd.jpg)

PSPNet 架构.（源于：[[1612.01105\] Pyramid Scene Parsing Network](http://link.zhihu.com/?target=https%3A//arxiv.org/abs/1612.01105)）

Large Kernel Matters

> Large Kernel Matters -- Improve Semantic Segmentation by Global Convolutional Network
> Submitted on 8 Mar 2017
> [Arxiv Link](http://link.zhihu.com/?target=https%3A//arxiv.org/abs/1703.02719)

主要贡献：

- 提出具有大型核卷积的编码器-解码器架构

相关解释：

语义分割需要同时进行分割，并对分割目标分类。由于语义分割架构中无法使用全连接层，文中采用带有大核函数的卷积替代全连接层。

采用大型核卷积的另外一个原因是，虽然ResNet等更深层的网络拥有较大的感受野，但[相关研究](http://link.zhihu.com/?target=https%3A//arxiv.org/abs/1412.6856)表明网络更宜收集较小区域（有效感受野）内的信息。

大型核的卷积拥有更多参数，所以需要耗费更多计算量。因此，论文将![k \times k](http://www.zhihu.com/equation?tex=k+%5Ctimes+k)的卷积近似表示为![k \times k \times 1](http://www.zhihu.com/equation?tex=k+%5Ctimes+k+%5Ctimes+1)、![k \times 1](http://www.zhihu.com/equation?tex=k+%5Ctimes+1)和![1\times k](http://www.zhihu.com/equation?tex=1%5Ctimes+k)的卷积的加和，论文中称该模块为全局卷积网络（Global Convolution Network，GCN）。

至于网络架构，编码器由ResNet（没有空洞卷积）构成，解码器则由GCNs和反卷积构成。此外，架构还用到了叫做边界细化（Boundary Refinement，BR）的简单残差块。

![img](https://pic2.zhimg.com/80/v2-266a286dda96b5c1c55057ef11a7e695_hd.jpg)



#### DeepLab v3

> Rethinking Atrous Convolution for Semantic Image Segmentation
> Submitted on 17 Jun 2017
> [Arxiv Link](http://link.zhihu.com/?target=https%3A//arxiv.org/abs/1706.05587)

主要贡献：

- 改进了金字塔型的空洞池化（atrous spatial pyramid pooling，ASPP）
- 级联了多个空洞卷积

相关解释：

与[DeepLabv2](http://link.zhihu.com/?target=http%3A//blog.qure.ai/notes/semantic-segmentation-deep-learning-review%23deeplab)和[空洞卷积（dilated convolutions）](http://link.zhihu.com/?target=http%3A//blog.qure.ai/notes/semantic-segmentation-deep-learning-review%23dilation)论文一样，论文也采用空洞/扩张卷积改进ResNet模型。改进后的ASPP包括图像层级特征连接、一个![1\times 1](http://www.zhihu.com/equation?tex=1%5Ctimes+1)的卷积以及三个![3\times 3](http://www.zhihu.com/equation?tex=3%5Ctimes+3)不同比率的空洞卷积，并构成序列。每个并行卷积层之后采用批量归一化操作。

级联模块是一个ResNet模块，但其卷积层由不同比率的空洞卷积构成。该模块类似于[空洞卷积（dilated convolutions）论文](http://link.zhihu.com/?target=http%3A//blog.qure.ai/notes/semantic-segmentation-deep-learning-review%23dilation)中的上下文模块（context module），不同点在于该模块直接应用于中间特征图（intermediate feature maps），而不是可信度地图（belief maps，可信度地图是通道数等于类别个数的CNN特征图）。

论文分别测试了这两个模型，他们的性能在验证集上表现相当，而带有ASPP的模型性能稍微好一点，这里的模型均没有使用CRF。

这两个模型性能均优于[DeepLabv2](http://link.zhihu.com/?target=http%3A//blog.qure.ai/notes/semantic-segmentation-deep-learning-review%23deeplab)中最优的模型。作者指出性能的提升得益于批量归一化操作和改进的多尺度上下文编码方式。

![img](https://pic3.zhimg.com/80/v2-eb20f194ce6509a0f7472cdc44808d51_hd.jpg)

DeepLabv3 ASPP.（源于：[[1706.05587\] Rethinking Atrous Convolution for Semantic Image Segmentation](http://link.zhihu.com/?target=https%3A//arxiv.org/abs/1706.05587)）